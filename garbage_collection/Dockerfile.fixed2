FROM python:3.10-slim-buster

# Set working directory inside the container
WORKDIR /app

# Copy requirements first (for better layer caching)
COPY pyproject.toml poetry.lock ./

# Install Poetry 
RUN pip install --no-cache-dir poetry && \
    pip install --no-cache-dir --upgrade pip

# Copy the rest of the application
COPY . .

# Explicitly add the vertexai package to pyproject.toml
RUN sed -i 's/\[tool.poetry.dependencies\]/[tool.poetry.dependencies]\nvertexai = "^1.71.1"\ngoogle-cloud-aiplatform = "^1.71.1"\ngoogle-genai = "^1.7.0"/' pyproject.toml

# Install the application with all dependencies
RUN poetry install

# Make run.sh executable
RUN chmod +x run.sh

# Set environment variable for Google credentials
ENV GOOGLE_APPLICATION_CREDENTIALS=/app/google-service-account.json
# Default to mock provider if no credentials
ENV USE_MOCK_PROVIDER=true

# Create a entrypoint script that checks credentials and selects provider
RUN echo '#!/bin/bash\n\
# Check if USE_MOCK_PROVIDER is true or if credentials file does not exist\n\
if [ "$USE_MOCK_PROVIDER" = "true" ] || [ ! -f "$GOOGLE_APPLICATION_CREDENTIALS" ]; then\n\
    echo "Using mock LLM provider..."\n\
    # Update config files to use mock provider\n\
    if grep -q "LLM_PROVIDER" /app/configs/financial_advisory.py; then\n\
        sed -i '\''s/LLM_PROVIDER = "vertex_ai"/LLM_PROVIDER = "mock"/'\'' /app/configs/financial_advisory.py\n\
    else\n\
        sed -i '\''s/# LLM Settings/# LLM Settings\\nLLM_PROVIDER = "mock"/'\'' /app/configs/financial_advisory.py\n\
    fi\n\
    exec poetry run python run_financial_advisory_mock.py "$@"\n\
else\n\
    echo "Using Vertex AI provider with credentials at $GOOGLE_APPLICATION_CREDENTIALS"\n\
    # Make sure config uses vertex_ai provider\n\
    if grep -q "LLM_PROVIDER" /app/configs/financial_advisory.py; then\n\
        sed -i '\''s/LLM_PROVIDER = "mock"/LLM_PROVIDER = "vertex_ai"/'\'' /app/configs/financial_advisory.py\n\
    else\n\
        sed -i '\''s/# LLM Settings/# LLM Settings\\nLLM_PROVIDER = "vertex_ai"/'\'' /app/configs/financial_advisory.py\n\
    fi\n\
    # Verify imports are available\n\
    if poetry run python -c "import vertexai; import google.cloud.aiplatform; import google.genai; print('\''Imports successful\'')" &>/dev/null; then\n\
        echo "Vertex AI packages imported successfully"\n\
    else\n\
        echo "Failed to import Vertex AI packages. Falling back to mock provider."\n\
        sed -i '\''s/LLM_PROVIDER = "vertex_ai"/LLM_PROVIDER = "mock"/'\'' /app/configs/financial_advisory.py\n\
        exec poetry run python run_financial_advisory_mock.py "$@"\n\
    fi\n\
    # All checks passed, run with Vertex AI\n\
    echo "Running with Vertex AI provider..."\n\
    exec poetry run python run_financial_advisory.py "$@"\n\
fi' > /app/docker-entrypoint.sh

# Make the entrypoint script executable
RUN chmod +x /app/docker-entrypoint.sh

# Set the command to run when the container starts
ENTRYPOINT ["/app/docker-entrypoint.sh"]