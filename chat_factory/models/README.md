# Models Directory README

This directory contains the data models for the `chat-factory` application. These models are used to define the structure of the data that is used and generated by the framework.

## Overview

The `models` package uses Python's `dataclasses` to create strongly-typed data structures. This provides several benefits:

*   **Data Validation:** Dataclasses (and Pydantic models, if used) can automatically validate the data that is passed to them, ensuring that it conforms to the expected structure and types.
*   **IDE Support:** Using dataclasses provides better autocompletion and type checking in modern IDEs.
*   **Serialization:** Dataclasses can be easily serialized to and from different formats, such as JSON.

## Components

### `conversation.py`

This file defines the data models for the conversation data structures:

*   **`ChatLine`:** Represents a single line of conversation, including the speaker, the text, and a timestamp.
*   **`SingleConversation`:** Represents a single conversation, including metadata like the conversation ID, category, and topic, as well as a list of `ChatLine` objects.
*   **`ConversationFile`:** Represents a file containing multiple conversations between the same advisor and client.

### `taxonomy.py`

This file defines the data models for the taxonomy data structures:

*   **`TaxonomyTopic`:** Represents a single topic in a taxonomy, including the category, topic, and subtopic.
*   **`Taxonomy`:** Represents a complete taxonomy, including a list of topics and metadata about the different conversation types.

## How the Models are Used

These data models are used throughout the application to ensure data consistency:

*   The `TaxonomyStrategy` uses the `Taxonomy` and `TaxonomyTopic` models to parse and represent the taxonomy files.
*   The `SyntheticChatGenerator` uses the `ConversationFile`, `SingleConversation`, and `ChatLine` models to create the generated conversation data.
*   The `GenerationStrategy` uses these models to structure the data that is passed to the LLM and to parse the LLM's response.
